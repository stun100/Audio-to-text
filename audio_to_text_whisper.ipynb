{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16XQ-LqxQQ0kZ_pEBXdQrfPMHnZtS-swv",
      "authorship_tag": "ABX9TyOh4YwVFzMOlXNctBW10gGH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stun100/Audio-to-text/blob/main/audio_to_text_whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Requirements"
      ],
      "metadata": {
        "id": "FlpbsetTS_Pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faster-whisper\n",
        "!pip install pydub\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "O8U27uqvNP7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24338b6d-e0e9-4c23-fc55-250ee84c37df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faster-whisper\n",
            "  Downloading faster_whisper-0.6.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting av==10.* (from faster-whisper)\n",
            "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctranslate2<4,>=3.10 (from faster-whisper)\n",
            "  Downloading ctranslate2-3.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.13 (from faster-whisper)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.13.* (from faster-whisper)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.10->faster-whisper) (1.22.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.10->faster-whisper) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (23.1)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (23.3.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.11.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Installing collected packages: tokenizers, av, humanfriendly, ctranslate2, huggingface-hub, coloredlogs, onnxruntime, faster-whisper\n",
            "Successfully installed av-10.0.0 coloredlogs-15.0.1 ctranslate2-3.16.0 faster-whisper-0.6.0 huggingface-hub-0.15.1 humanfriendly-10.0 onnxruntime-1.15.1 tokenizers-0.13.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.8 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Imports"
      ],
      "metadata": {
        "id": "6pAFVanXTL0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from faster_whisper import WhisperModel\n",
        "import time\n",
        "from pydub import AudioSegment\n",
        "import math\n",
        "import os\n",
        "import openai\n",
        "import requests\n",
        "\n",
        "openai.api_key = \"\"\n",
        "\n",
        "def split_audio(input_path, output_path, segment_length_min):\n",
        "\n",
        "    filename, audio_format = filename_and_format_from_path(input_path)\n",
        "\n",
        "    audio_file = AudioSegment.from_file(input_path, format=audio_format)\n",
        "\n",
        "    # set the segment length to 15 minutes (in milliseconds)\n",
        "    segment_length_millisec = segment_length_min * 60 * 1000\n",
        "\n",
        "    num_segments = math.ceil(len(audio_file) / segment_length_millisec)\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        start = i * segment_length_millisec\n",
        "        end = min((i+1) * segment_length_millisec, len(audio_file))\n",
        "        segment = audio_file[start:end]\n",
        "        if (output_path == \"\"):\n",
        "            segment.export(f\"{filename}_{i+1}.mp3\", format=\"mp3\", codec=\"libmp3lame\")\n",
        "        else:\n",
        "            segment.export(f\"{output_path}/{filename}_{i+1}.mp3\", format=\"mp3\", codec=\"libmp3lame\")\n",
        "\n",
        "\n",
        "def filename_and_format_from_path(path):\n",
        "    splitted_path = path.split(\"/\")\n",
        "    return splitted_path[-1].split(\".\")"
      ],
      "metadata": {
        "id": "JViHk0SEStKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Code"
      ],
      "metadata": {
        "id": "DQQ-g01alath"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Splitting audio file in multiple segments"
      ],
      "metadata": {
        "id": "QgUBnj4rld5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numero_lezione = 8\n",
        "numero_di_audio = 1\n",
        "input_path = f\"/content/drive/MyDrive/EMB_AudioSegments/Lecture_{numero_lezione}/audio_original\"\n",
        "output_path = f\"/content/drive/MyDrive/EMB_AudioSegments/Lecture_{numero_lezione}/audio_segments\""
      ],
      "metadata": {
        "id": "cNdrrf6jKj-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#argomento = \"Drammaturgia\"\n",
        "\n",
        "for i in range(numero_di_audio):\n",
        "  split_audio(input_path+ f'/Drammaturgia{numero_lezione}-{i+1}.m4a',output_path,30)"
      ],
      "metadata": {
        "id": "p0CSB-XgTa_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 audio-to-text using Whisper Model"
      ],
      "metadata": {
        "id": "QURoajMolj0L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tTyEPWdM4S1",
        "outputId": "652f4b08-8f04-49a9-c5d0-77363e4da8fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:libav.mp3:Estimating duration from bitrate, this may be inaccurate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sec: : 180.57182335853577 s\n"
          ]
        }
      ],
      "source": [
        "model_size = \"large-v2\"\n",
        "\n",
        "# Run on GPU with FP16\n",
        "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "\n",
        "# or run on GPU with INT8\n",
        "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
        "# or run on CPU with INT8\n",
        "# model = WhisperModel(model_size, device=\"auto\", compute_type=\"int8\")\n",
        "#for i in range(numero_lezione):\n",
        "\n",
        "#original = f\"/content/drive/MyDrive/EMB_AudioSegments/Lecture_{numero_lezione}/audio_segments/Drammaturgia{numero_lezione}-2_{y+1}.mp3\"\n",
        "#original2 = f'/content/drive/MyDrive/EMB_AudioSegments/Lecture_{numero_lezione}/audio_transcripts/Drammaturgia{numero_lezione}-2_{y+1}.txt'\n",
        "\n",
        "n_audio = 1\n",
        "\n",
        "for y in range(1):\n",
        "    time_stamp2 = time.time()\n",
        "    segments, info = model.transcribe(f\"/content/drive/MyDrive/EMB_AudioSegments/Lecture_{numero_lezione}/audio_segments/Drammaturgia{numero_lezione}-{n_audio}_{y+1}.mp3\", beam_size=5, language=\"it\")\n",
        "    with open(f'/content/drive/MyDrive/EMB_AudioSegments/Lecture_{numero_lezione}/audio_transcripts/Drammaturgia{numero_lezione}-{n_audio}_{y+1}.txt', 'w') as f:\n",
        "      for segment in segments:\n",
        "          # print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
        "          f.write(segment.text)\n",
        "    time_stamp3 = time.time()\n",
        "    print(\"sec: :\", time_stamp3-time_stamp2, \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = 4\n",
        "time_stamp2 = time.time()\n",
        "segments, info = model.transcribe(f\"/content/drive/MyDrive/EMB_AudioSegments/Lecture_{numero_lezione}/audio_segments/Drammaturgia{numero_lezione}-{n_audio}_{y+1}.mp3\", beam_size=5, language=\"it\")\n",
        "with open(f'/content/drive/MyDrive/EMB_AudioSegments/Lecture_{numero_lezione}/audio_transcripts/Drammaturgia{numero_lezione}-{n_audio}_{y+1}.txt', 'w') as f:\n",
        "  for segment in segments:\n",
        "      # print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
        "      f.write(segment.text)\n",
        "time_stamp3 = time.time()\n",
        "print(\"sec: :\", time_stamp3-time_stamp2, \"s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydPN2XNVBXLl",
        "outputId": "bdb940ab-5a46-486a-8399-a7aaa189bafe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:libav.mp3:Estimating duration from bitrate, this may be inaccurate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sec: : 209.78843021392822 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_all_models():\n",
        "    model_list = openai.Model.list()['data']\n",
        "    model_ids = [x['id'] for x in model_list]\n",
        "    model_ids.sort()\n",
        "    print(model_ids)\n",
        "list_all_models()\n",
        "time_stamp2 = time.time()\n",
        "\n",
        "with open('/content/drive/MyDrive/EMB_AudioSegments/Final/test_text.txt', 'r') as file:\n",
        "    data_file = file.read()\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model = \"gpt-4-0314\",\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": data_file + \" This is the transcript of a lecture. Some words of the transcripts may be wrong so correct it when you write down the summary. Please give me a summary of this test such that I can used for study later during the exam session.\"},\n",
        "    ]\n",
        ")\n",
        "time_stamp3 = time.time()\n",
        "print(\"sec:\", time_stamp3-time_stamp2, \"s\")\n",
        "print(response['choices'][0][\"message\"][\"content\"])\n",
        "print(\"total_tokens:\", response['usage'][\"total_tokens\"])\n",
        "print(\"start writing\")\n",
        "with open('/content/drive/MyDrive/EMB_AudioSegments/Final/SummaryTest.txt', 'w') as f:\n",
        "    f.write(response['choices'][0][\"message\"][\"content\"])\n",
        "print(\"stop writing\")\n"
      ],
      "metadata": {
        "id": "LIFzUbT52X2z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}